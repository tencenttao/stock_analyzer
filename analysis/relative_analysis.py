# -*- coding: utf-8 -*-
"""
ç›¸å¯¹æ”¶ç›Šåˆ†ææ¨¡å—

åˆ†æè·‘èµ¢/è·‘è¾“å¤§ç›˜çš„è‚¡ç¥¨ç‰¹å¾å·®å¼‚ï¼Œæ‰¾å‡ºæœ‰æ•ˆçš„é¢„æµ‹æŒ‡æ ‡ã€‚

æ ¸å¿ƒæ€è·¯ï¼š
1. å°†è‚¡ç¥¨æŒ‰ç›¸å¯¹æ”¶ç›Šï¼ˆvså¤§ç›˜ï¼‰åˆ†ä¸ºä¸‰ç»„ï¼šè·‘èµ¢ã€æŒå¹³ã€è·‘è¾“
2. å¯¹æ¯”å„ç»„åœ¨ä¹°å…¥æ—¶çš„ç‰¹å¾å·®å¼‚
3. æ‰¾å‡ºèƒ½æœ‰æ•ˆåŒºåˆ†è·‘èµ¢/è·‘è¾“çš„æŒ‡æ ‡
4. ä¸ºç­–ç•¥ä¼˜åŒ–æä¾›æ•°æ®æ”¯æ’‘

ä½¿ç”¨æ–¹æ³•:
    python -m analysis.relative_analysis 2024-01-01 2024-12-31
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import logging
import json
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
import statistics

from data.manager import DataManager
from core.types import StockData

logger = logging.getLogger(__name__)


@dataclass
class StockPerformance:
    """è‚¡ç¥¨è¡¨ç°æ•°æ®"""
    code: str
    name: str
    month_date: str
    
    # æ”¶ç›Šæ•°æ®
    stock_return: float      # è‚¡ç¥¨æ”¶ç›Šç‡
    benchmark_return: float  # åŸºå‡†æ”¶ç›Šç‡
    relative_return: float   # ç›¸å¯¹æ”¶ç›Šï¼ˆè¶…é¢æ”¶ç›Šï¼‰
    
    # ä¹°å…¥æ—¶ç‰¹å¾
    price: float = 0.0
    change_pct: float = 0.0
    turnover_rate: float = 0.0
    momentum_20d: float = 0.0
    momentum_60d: float = 0.0
    pe_ratio: float = 0.0
    pb_ratio: float = 0.0
    roe: float = 0.0
    profit_growth: float = 0.0
    dividend_yield: float = 0.0
    
    # åˆ†ç»„
    group: str = ""  # 'outperform', 'neutral', 'underperform'
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class GroupStats:
    """ç»„åˆ«ç»Ÿè®¡"""
    group_name: str
    count: int
    pct: float  # å æ¯”
    
    # æ”¶ç›Šç»Ÿè®¡
    avg_return: float
    avg_relative: float
    
    # å„æŒ‡æ ‡å‡å€¼
    avg_momentum_20d: float = 0.0
    avg_change_pct: float = 0.0
    avg_pe_ratio: float = 0.0
    avg_pb_ratio: float = 0.0
    avg_roe: float = 0.0
    avg_profit_growth: float = 0.0
    avg_turnover_rate: float = 0.0
    avg_dividend_yield: float = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass 
class FeatureEffectiveness:
    """ç‰¹å¾æœ‰æ•ˆæ€§åˆ†æ"""
    feature_name: str
    
    # è·‘èµ¢ç»„ vs è·‘è¾“ç»„çš„å‡å€¼å·®å¼‚
    outperform_avg: float
    underperform_avg: float
    diff: float
    diff_pct: float  # å·®å¼‚ç™¾åˆ†æ¯”
    
    # ä¸ç›¸å¯¹æ”¶ç›Šçš„ç›¸å…³æ€§
    correlation: float = 0.0
    
    # åŒºåˆ†èƒ½åŠ›è¯„åˆ† (0-100)
    effectiveness_score: float = 0.0
    
    # å»ºè®®
    suggestion: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class RelativeAnalysisResult:
    """ç›¸å¯¹æ”¶ç›Šåˆ†æç»“æœ"""
    start_date: str
    end_date: str
    total_months: int
    total_samples: int
    
    # åˆ†ç»„ç»Ÿè®¡
    outperform_stats: GroupStats = None
    neutral_stats: GroupStats = None
    underperform_stats: GroupStats = None
    
    # ç‰¹å¾æœ‰æ•ˆæ€§æ’å
    feature_effectiveness: List[FeatureEffectiveness] = field(default_factory=list)
    
    # æœˆåº¦ç»Ÿè®¡
    monthly_outperform_rate: List[float] = field(default_factory=list)
    
    # å…³é”®å‘ç°
    key_findings: List[str] = field(default_factory=list)
    
    # ç­–ç•¥å»ºè®®
    suggestions: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        if self.outperform_stats:
            result['outperform_stats'] = self.outperform_stats.to_dict()
        if self.neutral_stats:
            result['neutral_stats'] = self.neutral_stats.to_dict()
        if self.underperform_stats:
            result['underperform_stats'] = self.underperform_stats.to_dict()
        result['feature_effectiveness'] = [f.to_dict() for f in self.feature_effectiveness]
        return result
    
    def save_to_json(self, filepath: str):
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, ensure_ascii=False, indent=2)
        logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {filepath}")


class RelativeAnalyzer:
    """ç›¸å¯¹æ”¶ç›Šåˆ†æå™¨"""
    
    # è·‘è¾“é˜ˆå€¼ï¼ˆç›¸å¯¹æ”¶ç›Šä½äºæ­¤å€¼è§†ä¸ºè·‘è¾“ï¼‰
    UNDERPERFORM_THRESHOLD = -5.0
    
    def __init__(self, data_source: DataManager = None):
        self.data_source = data_source or DataManager(use_cache=True)
    
    def analyze(
        self,
        start_date: str,
        end_date: str,
        index_code: str = '000300',
        save_path: str = None,
    ) -> RelativeAnalysisResult:
        """æ‰§è¡Œç›¸å¯¹æ”¶ç›Šåˆ†æ"""
        logger.info("=" * 60)
        logger.info("ğŸ“Š ç›¸å¯¹æ”¶ç›Šåˆ†æï¼ˆè·‘èµ¢/è·‘è¾“å¤§ç›˜ï¼‰")
        logger.info("=" * 60)
        logger.info(f"ğŸ“… åˆ†ææœŸé—´: {start_date} ~ {end_date}")
        logger.info(f"ğŸ“ˆ åŸºå‡†æŒ‡æ•°: {index_code}")
        logger.info("=" * 60)
        
        # è·å–æ¯æœˆç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥
        trading_days = self.data_source.get_first_trading_days(start_date, end_date)
        if not trading_days or len(trading_days) < 2:
            logger.error("äº¤æ˜“æ—¥å†è·å–å¤±è´¥")
            return None
        
        logger.info(f"ğŸ“† åˆ†æå‘¨æœŸ: {len(trading_days)-1}ä¸ªæœˆ")
        
        # æ”¶é›†æ‰€æœ‰è‚¡ç¥¨è¡¨ç°æ•°æ®
        all_performances = []
        monthly_outperform_rates = []
        
        for i in range(len(trading_days) - 1):
            buy_date = trading_days[i]
            sell_date = trading_days[i + 1]
            
            logger.info(f"\nğŸ“… ç¬¬{i+1}ä¸ªæœˆ: {buy_date} â†’ {sell_date}")
            
            performances, outperform_rate = self._analyze_single_month(
                buy_date, sell_date, index_code
            )
            
            if performances:
                all_performances.extend(performances)
                monthly_outperform_rates.append(outperform_rate)
        
        if not all_performances:
            logger.error("æ— æœ‰æ•ˆæ•°æ®")
            return None
        
        # åˆ†ç»„ç»Ÿè®¡
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š æ±‡æ€»ç»Ÿè®¡...")
        
        outperform = [p for p in all_performances if p.group == 'outperform']
        neutral = [p for p in all_performances if p.group == 'neutral']
        underperform = [p for p in all_performances if p.group == 'underperform']
        
        total = len(all_performances)
        
        outperform_stats = self._calc_group_stats('è·‘èµ¢ç»„', outperform, total)
        neutral_stats = self._calc_group_stats('æŒå¹³ç»„', neutral, total)
        underperform_stats = self._calc_group_stats('è·‘è¾“ç»„', underperform, total)
        
        # ç‰¹å¾æœ‰æ•ˆæ€§åˆ†æ
        feature_effectiveness = self._analyze_feature_effectiveness(
            outperform, underperform, all_performances
        )
        
        # ç”Ÿæˆå‘ç°å’Œå»ºè®®
        key_findings = self._generate_findings(
            outperform_stats, underperform_stats, feature_effectiveness
        )
        suggestions = self._generate_suggestions(feature_effectiveness)
        
        # æ„å»ºç»“æœ
        result = RelativeAnalysisResult(
            start_date=start_date,
            end_date=end_date,
            total_months=len(trading_days) - 1,
            total_samples=total,
            outperform_stats=outperform_stats,
            neutral_stats=neutral_stats,
            underperform_stats=underperform_stats,
            feature_effectiveness=feature_effectiveness,
            monthly_outperform_rate=monthly_outperform_rates,
            key_findings=key_findings,
            suggestions=suggestions,
        )
        
        # æ‰“å°æŠ¥å‘Š
        self._print_report(result)
        
        if save_path:
            result.save_to_json(save_path)
        
        return result
    
    def _analyze_single_month(
        self,
        buy_date: str,
        sell_date: str,
        index_code: str,
    ) -> Tuple[List[StockPerformance], float]:
        """åˆ†æå•æœˆè¡¨ç°"""
        
        # è·å–æˆåˆ†è‚¡
        stock_codes = self.data_source.get_index_constituents(index_code, buy_date)
        if not stock_codes:
            return [], 0.0
        
        # è·å–åŸºå‡†æ”¶ç›Š
        benchmark_return = self.data_source.get_index_return(index_code, buy_date, sell_date)
        logger.info(f"   åŸºå‡†æ”¶ç›Š: {benchmark_return:+.2f}%")
        
        # è·å–ä¹°å…¥æ—¥æ•°æ®
        buy_data_list = []
        for code in stock_codes:
            stock = self.data_source.get_stock_data(code, buy_date)
            if stock and stock.price > 0:
                buy_data_list.append(stock)
        
        # è·å–å–å‡ºæ—¥æ•°æ®ï¼Œè®¡ç®—æ”¶ç›Š
        performances = []
        for buy_stock in buy_data_list:
            sell_stock = self.data_source.get_stock_data(buy_stock.code, sell_date)
            if sell_stock and sell_stock.price > 0:
                stock_return = (sell_stock.price - buy_stock.price) / buy_stock.price * 100
                relative_return = stock_return - benchmark_return
                
                # åˆ†ç»„
                if relative_return > 0:
                    group = 'outperform'
                elif relative_return > self.UNDERPERFORM_THRESHOLD:
                    group = 'neutral'
                else:
                    group = 'underperform'
                
                perf = StockPerformance(
                    code=buy_stock.code,
                    name=buy_stock.name,
                    month_date=buy_date,
                    stock_return=stock_return,
                    benchmark_return=benchmark_return,
                    relative_return=relative_return,
                    price=buy_stock.price,
                    change_pct=buy_stock.change_pct or 0,
                    turnover_rate=buy_stock.turnover_rate or 0,
                    momentum_20d=buy_stock.momentum_20d or 0,
                    momentum_60d=buy_stock.momentum_60d or 0,
                    pe_ratio=buy_stock.pe_ratio or 0,
                    pb_ratio=buy_stock.pb_ratio or 0,
                    roe=buy_stock.roe or 0,
                    profit_growth=buy_stock.profit_growth or 0,
                    dividend_yield=buy_stock.dividend_yield or 0,
                    group=group,
                )
                performances.append(perf)
        
        # ç»Ÿè®¡
        outperform_count = sum(1 for p in performances if p.group == 'outperform')
        underperform_count = sum(1 for p in performances if p.group == 'underperform')
        outperform_rate = outperform_count / len(performances) * 100 if performances else 0
        
        logger.info(f"   æœ‰æ•ˆæ ·æœ¬: {len(performances)}")
        logger.info(f"   ğŸŸ¢ è·‘èµ¢: {outperform_count} ({outperform_rate:.1f}%)")
        logger.info(f"   ğŸ”´ è·‘è¾“: {underperform_count} ({underperform_count/len(performances)*100:.1f}%)")
        
        return performances, outperform_rate
    
    def _calc_group_stats(
        self,
        name: str,
        performances: List[StockPerformance],
        total: int,
    ) -> GroupStats:
        """è®¡ç®—ç»„åˆ«ç»Ÿè®¡"""
        if not performances:
            return GroupStats(
                group_name=name, count=0, pct=0,
                avg_return=0, avg_relative=0
            )
        
        n = len(performances)
        
        def safe_mean(values):
            valid = [v for v in values if v != 0 and v is not None]
            return statistics.mean(valid) if valid else 0
        
        return GroupStats(
            group_name=name,
            count=n,
            pct=n / total * 100,
            avg_return=statistics.mean([p.stock_return for p in performances]),
            avg_relative=statistics.mean([p.relative_return for p in performances]),
            avg_momentum_20d=safe_mean([p.momentum_20d for p in performances]),
            avg_change_pct=safe_mean([p.change_pct for p in performances]),
            avg_pe_ratio=safe_mean([p.pe_ratio for p in performances if 0 < p.pe_ratio < 200]),
            avg_pb_ratio=safe_mean([p.pb_ratio for p in performances if 0 < p.pb_ratio < 20]),
            avg_roe=safe_mean([p.roe for p in performances]),
            avg_profit_growth=safe_mean([p.profit_growth for p in performances if -100 < p.profit_growth < 200]),
            avg_turnover_rate=safe_mean([p.turnover_rate for p in performances]),
            avg_dividend_yield=safe_mean([p.dividend_yield for p in performances]),
        )
    
    def _analyze_feature_effectiveness(
        self,
        outperform: List[StockPerformance],
        underperform: List[StockPerformance],
        all_data: List[StockPerformance],
    ) -> List[FeatureEffectiveness]:
        """åˆ†æå„ç‰¹å¾çš„æœ‰æ•ˆæ€§"""
        
        features = [
            ('momentum_20d', '20æ—¥åŠ¨é‡'),
            ('change_pct', 'ä¹°å…¥æ—¥æ¶¨å¹…'),
            ('pe_ratio', 'å¸‚ç›ˆç‡PE'),
            ('pb_ratio', 'å¸‚å‡€ç‡PB'),
            ('roe', 'ROE'),
            ('profit_growth', 'åˆ©æ¶¦å¢é•¿ç‡'),
            ('turnover_rate', 'æ¢æ‰‹ç‡'),
            ('dividend_yield', 'è‚¡æ¯ç‡'),
        ]
        
        results = []
        
        for attr, name in features:
            # è·å–ä¸¤ç»„çš„å€¼
            out_values = [getattr(p, attr) for p in outperform if getattr(p, attr) != 0]
            under_values = [getattr(p, attr) for p in underperform if getattr(p, attr) != 0]
            
            # è¿‡æ»¤å¼‚å¸¸å€¼
            if attr == 'pe_ratio':
                out_values = [v for v in out_values if 0 < v < 200]
                under_values = [v for v in under_values if 0 < v < 200]
            if attr == 'profit_growth':
                out_values = [v for v in out_values if -100 < v < 300]
                under_values = [v for v in under_values if -100 < v < 300]
            
            if not out_values or not under_values:
                continue
            
            out_avg = statistics.mean(out_values)
            under_avg = statistics.mean(under_values)
            diff = out_avg - under_avg
            
            # é¿å…é™¤é›¶
            base = abs(under_avg) if under_avg != 0 else abs(out_avg) if out_avg != 0 else 1
            diff_pct = diff / base * 100 if base != 0 else 0
            
            # è®¡ç®—ç›¸å…³æ€§ï¼ˆç®€åŒ–ç‰ˆï¼šç”¨å·®å¼‚æ¯”ä¾‹ä½œä¸ºåŒºåˆ†èƒ½åŠ›è¯„åˆ†ï¼‰
            effectiveness = min(100, abs(diff_pct))
            
            # ç”Ÿæˆå»ºè®®
            if effectiveness > 30:
                if diff > 0:
                    suggestion = f"âœ… é€‰æ‹©é«˜{name}è‚¡ç¥¨"
                else:
                    suggestion = f"âœ… é€‰æ‹©ä½{name}è‚¡ç¥¨"
            elif effectiveness > 15:
                suggestion = f"âš ï¸ {name}æœ‰ä¸€å®šåŒºåˆ†èƒ½åŠ›"
            else:
                suggestion = f"âŒ {name}åŒºåˆ†èƒ½åŠ›å¼±"
            
            results.append(FeatureEffectiveness(
                feature_name=name,
                outperform_avg=out_avg,
                underperform_avg=under_avg,
                diff=diff,
                diff_pct=diff_pct,
                effectiveness_score=effectiveness,
                suggestion=suggestion,
            ))
        
        # æŒ‰æœ‰æ•ˆæ€§æ’åº
        results.sort(key=lambda x: x.effectiveness_score, reverse=True)
        
        return results
    
    def _generate_findings(
        self,
        outperform: GroupStats,
        underperform: GroupStats,
        features: List[FeatureEffectiveness],
    ) -> List[str]:
        """ç”Ÿæˆå…³é”®å‘ç°"""
        findings = []
        
        findings.append(f"ğŸ“Š è·‘èµ¢å¤§ç›˜æ¯”ä¾‹: {outperform.pct:.1f}% ({outperform.count}åª)")
        findings.append(f"ğŸ“Š è·‘è¾“å¤§ç›˜æ¯”ä¾‹: {underperform.pct:.1f}% ({underperform.count}åª)")
        findings.append(f"ğŸ’° è·‘èµ¢ç»„å¹³å‡ç›¸å¯¹æ”¶ç›Š: +{outperform.avg_relative:.2f}%")
        findings.append(f"ğŸ’° è·‘è¾“ç»„å¹³å‡ç›¸å¯¹æ”¶ç›Š: {underperform.avg_relative:.2f}%")
        
        # æœ€æœ‰æ•ˆçš„ç‰¹å¾
        if features:
            top_feature = features[0]
            findings.append(f"ğŸ¯ æœ€æœ‰æ•ˆåŒºåˆ†æŒ‡æ ‡: {top_feature.feature_name} "
                          f"(è·‘èµ¢ç»„={top_feature.outperform_avg:.2f}, "
                          f"è·‘è¾“ç»„={top_feature.underperform_avg:.2f})")
        
        return findings
    
    def _generate_suggestions(
        self,
        features: List[FeatureEffectiveness],
    ) -> List[str]:
        """ç”Ÿæˆç­–ç•¥å»ºè®®"""
        suggestions = []
        
        # æ ¹æ®æœ‰æ•ˆç‰¹å¾ç”Ÿæˆå»ºè®®
        effective_features = [f for f in features if f.effectiveness_score > 20]
        
        if effective_features:
            suggestions.append("ğŸ“‹ æœ‰æ•ˆçš„ç­›é€‰æ¡ä»¶ï¼š")
            for f in effective_features[:5]:
                if f.diff > 0:
                    suggestions.append(f"   â€¢ ä¼˜é€‰é«˜{f.feature_name}ï¼šè·‘èµ¢ç»„å‡å€¼={f.outperform_avg:.2f}")
                else:
                    suggestions.append(f"   â€¢ ä¼˜é€‰ä½{f.feature_name}ï¼šè·‘èµ¢ç»„å‡å€¼={f.outperform_avg:.2f}")
        
        # é£é™©æ§åˆ¶å»ºè®®
        weak_features = [f for f in features if f.effectiveness_score < 10]
        if weak_features:
            names = [f.feature_name for f in weak_features[:3]]
            suggestions.append(f"âš ï¸ ä»¥ä¸‹æŒ‡æ ‡åŒºåˆ†èƒ½åŠ›å¼±ï¼Œä¸å®œä½œä¸ºä¸»è¦ç­›é€‰æ¡ä»¶ï¼š{', '.join(names)}")
        
        return suggestions
    
    def _print_report(self, result: RelativeAnalysisResult):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ“Š ç›¸å¯¹æ”¶ç›Šåˆ†ææŠ¥å‘Š")
        logger.info("=" * 70)
        
        logger.info(f"\nğŸ“… åˆ†ææœŸé—´: {result.start_date} ~ {result.end_date}")
        logger.info(f"ğŸ“ˆ åˆ†ææœˆæ•°: {result.total_months}")
        logger.info(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {result.total_samples}")
        
        # åˆ†ç»„ç»Ÿè®¡
        logger.info("\nğŸ“Š åˆ†ç»„ç»Ÿè®¡ï¼š")
        logger.info("-" * 60)
        logger.info(f"  {'ç»„åˆ«':<8} {'æ•°é‡':<8} {'å æ¯”':<10} {'å¹³å‡æ”¶ç›Š':<12} {'ç›¸å¯¹æ”¶ç›Š':<12}")
        logger.info("-" * 60)
        
        for stats in [result.outperform_stats, result.neutral_stats, result.underperform_stats]:
            if stats:
                logger.info(f"  {stats.group_name:<8} {stats.count:<8} "
                          f"{stats.pct:.1f}%{'':<6} "
                          f"{stats.avg_return:+.2f}%{'':<6} "
                          f"{stats.avg_relative:+.2f}%")
        
        # ç‰¹å¾å¯¹æ¯”
        logger.info("\nğŸ“Š è·‘èµ¢ç»„ vs è·‘è¾“ç»„ ç‰¹å¾å¯¹æ¯”ï¼š")
        logger.info("-" * 70)
        logger.info(f"  {'ç‰¹å¾':<12} {'è·‘èµ¢ç»„':<12} {'è·‘è¾“ç»„':<12} {'å·®å¼‚':<12} {'æœ‰æ•ˆæ€§':<10}")
        logger.info("-" * 70)
        
        for f in result.feature_effectiveness:
            logger.info(f"  {f.feature_name:<12} "
                       f"{f.outperform_avg:>10.2f} "
                       f"{f.underperform_avg:>10.2f} "
                       f"{f.diff:>+10.2f} "
                       f"{f.effectiveness_score:>8.1f}")
        
        # å…³é”®å‘ç°
        logger.info("\nğŸ” å…³é”®å‘ç°ï¼š")
        logger.info("-" * 60)
        for finding in result.key_findings:
            logger.info(f"  {finding}")
        
        # ç­–ç•¥å»ºè®®
        logger.info("\nğŸ’¡ ç­–ç•¥å»ºè®®ï¼š")
        logger.info("-" * 60)
        for suggestion in result.suggestions:
            logger.info(f"  {suggestion}")
        
        logger.info("\n" + "=" * 70)


def run_relative_analysis(
    start_date: str = '2024-01-01',
    end_date: str = '2024-12-31',
    save_path: str = None,
) -> RelativeAnalysisResult:
    """è¿è¡Œç›¸å¯¹æ”¶ç›Šåˆ†æ"""
    analyzer = RelativeAnalyzer()
    
    if save_path is None:
        os.makedirs('logs/analysis', exist_ok=True)
        save_path = f"logs/analysis/relative_analysis_{start_date}_{end_date}.json"
    
    return analyzer.analyze(
        start_date=start_date,
        end_date=end_date,
        save_path=save_path,
    )


if __name__ == '__main__':
    logging.basicConfig(
        level=logging.INFO,
        format='%(message)s'
    )
    
    start_date = sys.argv[1] if len(sys.argv) > 1 else '2024-01-01'
    end_date = sys.argv[2] if len(sys.argv) > 2 else '2024-12-31'
    
    result = run_relative_analysis(start_date=start_date, end_date=end_date)
    
    if result:
        print(f"\nâœ… åˆ†æå®Œæˆ")
